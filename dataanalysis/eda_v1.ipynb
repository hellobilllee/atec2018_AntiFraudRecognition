{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective of this competition is to use historical transaction data to predict the riskability of an new transactio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atec_anti_fraud_test_b.csv', 'atec_anti_fraud_train.csv']\n"
     ]
    }
   ],
   "source": [
    "# List files available\n",
    "print(os.listdir(\"../sourcedata/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"../sourcedata/atec_anti_fraud_train.csv\"\n",
    "test_file = \"../sourcedata/atec_anti_fraud_test_b.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_file,header=0,index_col=None)\n",
    "df_test = pd.read_csv(test_file,header=0,index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (994731, 300)\n",
      "testing data shape: (500538, 299)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data shape:\", df_train.shape)\n",
    "print(\"testing data shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>...</th>\n",
       "      <th>f288</th>\n",
       "      <th>f289</th>\n",
       "      <th>f290</th>\n",
       "      <th>f291</th>\n",
       "      <th>f292</th>\n",
       "      <th>f293</th>\n",
       "      <th>f294</th>\n",
       "      <th>f295</th>\n",
       "      <th>f296</th>\n",
       "      <th>f297</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f10eb20f31cf7063ee8bdbd1272214e4d7e0193c8dbce4...</td>\n",
       "      <td>0</td>\n",
       "      <td>20171103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100807.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>301.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d861929b67938d06538b910b9f6b85f5eb62b6ad7361ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>20170917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100805.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>302.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1270cb8a85eedd57672b2c6297fa5633e36773a2c3a351...</td>\n",
       "      <td>0</td>\n",
       "      <td>20171022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9fa009724ee7ff9d688ae321304fbc78f608cdabbfdd2b...</td>\n",
       "      <td>0</td>\n",
       "      <td>20171029</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100807.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>302.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1da482485d7e8bcefae7e9d0d1167cec3ac111cfa71d8b...</td>\n",
       "      <td>0</td>\n",
       "      <td>20171002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100805.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>302.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  label      date  f1  f2  \\\n",
       "0  f10eb20f31cf7063ee8bdbd1272214e4d7e0193c8dbce4...      0  20171103   0   0   \n",
       "1  d861929b67938d06538b910b9f6b85f5eb62b6ad7361ba...      0  20170917   0   1   \n",
       "2  1270cb8a85eedd57672b2c6297fa5633e36773a2c3a351...      0  20171022   0   0   \n",
       "3  9fa009724ee7ff9d688ae321304fbc78f608cdabbfdd2b...      0  20171029   0   0   \n",
       "4  1da482485d7e8bcefae7e9d0d1167cec3ac111cfa71d8b...      0  20171002   1   1   \n",
       "\n",
       "   f3  f4        f5  f6  f7  ...     f288   f289   f290  f291   f292   f293  \\\n",
       "0   0   0  100807.0   0   5  ...    301.0  312.0  328.0  85.0  302.0  201.0   \n",
       "1   1   1  100805.0   1   5  ...    302.0  324.0  391.0  13.0  302.0  160.0   \n",
       "2   1   0  100102.0   0   6  ...      NaN    NaN    NaN   NaN    NaN    NaN   \n",
       "3   0   1  100807.0   1   4  ...    302.0  322.0  341.0  57.0  251.0  175.0   \n",
       "4   0   1  100805.0   1   5  ...    302.0  301.0  301.0  74.0  302.0  182.0   \n",
       "\n",
       "    f294   f295  f296   f297  \n",
       "0  203.0  203.0  61.0  201.0  \n",
       "1  160.0  161.0   8.0  160.0  \n",
       "2    NaN    NaN   NaN    NaN  \n",
       "3  176.0  176.0  49.0  150.0  \n",
       "4  181.0  182.0  51.0  181.0  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"f\"+str(j) for j in range(1,20) if  j!=5]:\n",
    "    df_train[col] = df_train[col].astype(np.uint8)\n",
    "    df_test[col] = df_test[col].astype(np.uint8)\n",
    "#     df_train.loc[df_train[col],col].astype(np.uint8)\n",
    "#     df_test.loc[df_test[col],col].astype(np.uint8)\n",
    "# df_train.loc[df_train[\"label\"],\"label\"].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"id\"] = df_train[\"id\"].astype(str)\n",
    "# df_train.loc[df_train[\"label\"],\"label\"].astype(np.int8)\n",
    "# df_train[\"date\"] = df_train[\"date\"].astype(np.uint32)\n",
    "# df_test[\"id\"] = df_test[\"id\"].astype(str)\n",
    "# df_test[\"date\"] = df_test[\"date\"].astype(np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (994731, 300)\n"
     ]
    }
   ],
   "source": [
    "# df_train.drop_duplicates(inplace=True)\n",
    "print(\"training data shape:\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994731\n",
      "500538\n"
     ]
    }
   ],
   "source": [
    "print(df_train[\"id\"].nunique())\n",
    "print(df_test[\"id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "intersect_ = set(df_test[\"id\"].tolist()).intersection(df_train[\"id\"].tolist())\n",
    "print(len(intersect_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    977884\n",
       " 1     12122\n",
       "-1      4725\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version one: filter data with label -1\n",
    "# df_train = df_train.loc[df_train[\"label\"]>=0]\n",
    "# version two: \n",
    "df_train.loc[df_train[\"label\"]==-1,\"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    977884\n",
       "1     16847\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "df_train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"label\"] = df_train[\"label\"].astype(np.uint8)\n",
    "df_train_id = df_train[[\"id\",\"date\",\"label\"]]\n",
    "df_train.drop(labels=[\"id\",\"date\",\"label\"],axis=1,inplace=True)\n",
    "df_test_id = df_test[[\"id\",\"date\"]]\n",
    "df_test.drop(labels=[\"id\",\"date\"],axis=1,inplace=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f20', 'f21', 'f22', 'f23', 'f32', 'f33', 'f34', 'f35', 'f48', 'f49', 'f50', 'f51', 'f64', 'f65', 'f67', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f161', 'f162', 'f163', 'f164', 'f165']\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "anormaly_cols = []\n",
    "f_cols = df_train.columns\n",
    "for col in f_cols:\n",
    "#     print(col)\n",
    "    mean_train = df_train[col].mean()\n",
    "    std_train = df_train[col].std()\n",
    "    mean_test = df_test[col].mean()\n",
    "    std_test = df_test[col].std()\n",
    "    mean_diff = max(mean_train/mean_test,mean_test/mean_train)\n",
    "    std_diff = max(std_train/std_test,std_test/std_train)\n",
    "    if mean_diff>5 and  std_diff>5:\n",
    "        anormaly_cols.append(col)\n",
    "print(anormaly_cols)\n",
    "print(len(anormaly_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (994731, 234)\n",
      "testing data shape: (500538, 234)\n"
     ]
    }
   ],
   "source": [
    "df_train.drop(labels=anormaly_cols,axis=1,inplace=True)\n",
    "df_test.drop(labels=anormaly_cols,axis=1,inplace=True)\n",
    "gc.collect()\n",
    "print(\"training data shape:\", df_train.shape)\n",
    "print(\"testing data shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 234 columns.\n",
      "There are 216 columns that have missing values.\n",
      "Your selected dataframe has 234 columns.\n",
      "There are 216 columns that have missing values.\n"
     ]
    }
   ],
   "source": [
    "# Missing values statistics\n",
    "missing_values_train = missing_values_table(df_train)\n",
    "missing_values_test = missing_values_table(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Missing Values  % of Total Values\n",
      "f46          466775               93.3\n",
      "f43          466775               93.3\n",
      "f47          466775               93.3\n",
      "f45          466775               93.3\n",
      "f44          466775               93.3\n"
     ]
    }
   ],
   "source": [
    "# print(missing_values_train.head(40))\n",
    "# print(missing_values_test.head(60))\n",
    "# missing_values_train.to_csv(\"../statsfile/stats.csv\",mode=\"a\")\n",
    "# missing_values_test.to_csv(\"../statsfile/stats.csv\",mode=\"a\")\n",
    "print(missing_values_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    216\n",
       "int64       18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of each type of column\n",
    "df_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['f37', 'f38', 'f46', 'f45', 'f44', 'f43', 'f42', 'f41', 'f40', 'f39',\n",
      "       ...\n",
      "       'f230', 'f229', 'f228', 'f227', 'f226', 'f225', 'f224', 'f223', 'f222',\n",
      "       'f242'],\n",
      "      dtype='object', length=216)\n"
     ]
    }
   ],
   "source": [
    "print(missing_values_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "fourty_percent_na_cols_train = missing_values_train[missing_values_train[\"% of Total Values\"]>40].index.tolist() \n",
    "print(len(fourty_percent_na_cols_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "fourty_percent_na_cols_test = missing_values_test[missing_values_test[\"% of Total Values\"]>40].index.tolist() \n",
    "print(len(fourty_percent_na_cols_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "fourty_percent_na_cols = list(set(fourty_percent_na_cols_test+fourty_percent_na_cols_train))\n",
    "print(len(fourty_percent_na_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(labels=fourty_percent_na_cols,axis=1,inplace=True)\n",
    "df_test.drop(labels=fourty_percent_na_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (994731, 161)\n",
      "testing data shape: (500538, 161)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print(\"training data shape:\", df_train.shape)\n",
    "print(\"testing data shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (994731, 161)\n"
     ]
    }
   ],
   "source": [
    "df_train.drop_duplicates(inplace=True)\n",
    "print(\"training data shape:\", df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 161 columns.\n",
      "There are 143 columns that have missing values.\n",
      "Your selected dataframe has 161 columns.\n",
      "There are 143 columns that have missing values.\n"
     ]
    }
   ],
   "source": [
    "missing_values_train = missing_values_table(df_train)\n",
    "missing_values_test = missing_values_table(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Missing Values  % of Total Values\n",
      "f31           211036               21.2\n",
      "f28           211036               21.2\n",
      "f29           211036               21.2\n",
      "f30           211036               21.2\n",
      "f283          207585               20.9\n",
      "f288          207585               20.9\n",
      "f287          207585               20.9\n",
      "f286          207585               20.9\n",
      "f285          207585               20.9\n",
      "f284          207585               20.9\n",
      "      Missing Values  % of Total Values\n",
      "f31           134096               26.8\n",
      "f28           134096               26.8\n",
      "f29           134096               26.8\n",
      "f30           134096               26.8\n",
      "f283          132844               26.5\n",
      "f288          132844               26.5\n",
      "f287          132844               26.5\n",
      "f286          132844               26.5\n",
      "f285          132844               26.5\n",
      "f284          132844               26.5\n"
     ]
    }
   ],
   "source": [
    "print(missing_values_train.head(10))\n",
    "print(missing_values_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv(\"../transdata/train_drop_v1.csv\",header=True,index=False)\n",
    "# df_test.to_csv(\"../transdata/test_drop_v1.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  f1             f2             f3             f4  \\\n",
      "count  994731.000000  994731.000000  994731.000000  994731.000000   \n",
      "mean        0.726283       0.500948       0.699285       0.525461   \n",
      "std         0.651947       0.500363       0.640534       0.523872   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         1.000000       1.000000       1.000000       1.000000   \n",
      "75%         1.000000       1.000000       1.000000       1.000000   \n",
      "max         2.000000       2.000000       2.000000       2.000000   \n",
      "\n",
      "                  f5             f6             f7             f8  \\\n",
      "count  794906.000000  994731.000000  994731.000000  994731.000000   \n",
      "mean   100652.575330       0.701303       4.201802       1.404783   \n",
      "std      4023.235737       0.757799       1.922035       0.579449   \n",
      "min     10000.000000       0.000000       0.000000       0.000000   \n",
      "25%    100802.000000       0.000000       3.000000       1.000000   \n",
      "50%    100804.000000       1.000000       4.000000       1.000000   \n",
      "75%    100806.000000       1.000000       6.000000       2.000000   \n",
      "max    150406.000000       4.000000       7.000000       2.000000   \n",
      "\n",
      "                  f9            f10      ...                 f288  \\\n",
      "count  994731.000000  994731.000000      ...        787146.000000   \n",
      "mean        0.610099       0.872438      ...           159.532191   \n",
      "std         0.589819       0.695263      ...           149.126719   \n",
      "min         0.000000       0.000000      ...             1.000000   \n",
      "25%         0.000000       0.000000      ...             2.000000   \n",
      "50%         1.000000       1.000000      ...           301.000000   \n",
      "75%         1.000000       1.000000      ...           302.000000   \n",
      "max         2.000000       2.000000      ...           302.000000   \n",
      "\n",
      "                f289           f290           f291           f292  \\\n",
      "count  787146.000000  787146.000000  787146.000000  787146.000000   \n",
      "mean      164.423796     174.171849      57.639792     149.509402   \n",
      "std       152.228807     164.144148      63.122004     142.628265   \n",
      "min         1.000000       1.000000       1.000000       1.000000   \n",
      "25%         2.000000       3.000000       2.000000       2.000000   \n",
      "50%       301.000000     301.000000      26.000000     184.000000   \n",
      "75%       304.000000     306.000000     109.000000     301.000000   \n",
      "max       388.000000     669.000000     302.000000     302.000000   \n",
      "\n",
      "                f293           f294           f295           f296  \\\n",
      "count  787146.000000  787146.000000  787146.000000  787146.000000   \n",
      "mean      105.056598     105.243853     105.246376      41.244121   \n",
      "std       100.003140     100.155753     100.153540      45.658241   \n",
      "min         1.000000       1.000000       1.000000       1.000000   \n",
      "25%         2.000000       2.000000       2.000000       2.000000   \n",
      "50%       164.000000     164.000000     164.000000      17.000000   \n",
      "75%       199.000000     199.000000     199.000000      79.000000   \n",
      "max       299.000000     299.000000     299.000000     280.000000   \n",
      "\n",
      "                f297  \n",
      "count  787146.000000  \n",
      "mean       99.023500  \n",
      "std        96.240483  \n",
      "min         1.000000  \n",
      "25%         2.000000  \n",
      "50%       115.000000  \n",
      "75%       194.000000  \n",
      "max       299.000000  \n",
      "\n",
      "[8 rows x 161 columns]\n",
      "                  f1             f2             f3             f4  \\\n",
      "count  500538.000000  500538.000000  500538.000000  500538.000000   \n",
      "mean        0.782956       0.499778       0.764018       0.533124   \n",
      "std         0.673424       0.500012       0.665964       0.530509   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         1.000000       0.000000       1.000000       1.000000   \n",
      "75%         1.000000       1.000000       1.000000       1.000000   \n",
      "max         2.000000       2.000000       2.000000       2.000000   \n",
      "\n",
      "                  f5             f6             f7             f8  \\\n",
      "count  368260.000000  500538.000000  500538.000000  500538.000000   \n",
      "mean   101062.047111       0.801240       4.038343       1.400223   \n",
      "std      5254.407671       0.864518       1.922538       0.583340   \n",
      "min     50200.000000       0.000000       0.000000       0.000000   \n",
      "25%    100808.000000       0.000000       2.000000       1.000000   \n",
      "50%    100810.000000       1.000000       4.000000       1.000000   \n",
      "75%    100811.000000       1.000000       6.000000       2.000000   \n",
      "max    150501.000000       4.000000       7.000000       2.000000   \n",
      "\n",
      "                  f9            f10      ...                 f288  \\\n",
      "count  500538.000000  500538.000000      ...        367694.000000   \n",
      "mean        0.640163       0.902341      ...           157.806018   \n",
      "std         0.609232       0.701122      ...           148.906218   \n",
      "min         0.000000       0.000000      ...             1.000000   \n",
      "25%         0.000000       0.000000      ...             2.000000   \n",
      "50%         1.000000       1.000000      ...           301.000000   \n",
      "75%         1.000000       1.000000      ...           302.000000   \n",
      "max         2.000000       2.000000      ...           302.000000   \n",
      "\n",
      "                f289           f290           f291           f292  \\\n",
      "count  367694.000000  367694.000000  367694.000000  367694.000000   \n",
      "mean      160.465194     162.058500      65.774892     147.377545   \n",
      "std       151.638868     158.336152      76.510247     142.765566   \n",
      "min         1.000000       1.000000       1.000000       1.000000   \n",
      "25%         2.000000       3.000000       2.000000       2.000000   \n",
      "50%       301.000000     301.000000      22.000000     161.000000   \n",
      "75%       302.000000     302.000000     124.000000     301.000000   \n",
      "max       833.000000    1712.000000     302.000000     302.000000   \n",
      "\n",
      "                f293           f294           f295           f296  \\\n",
      "count  367694.000000  367694.000000  367694.000000  367694.000000   \n",
      "mean      114.659189     114.727706     114.739563      51.327696   \n",
      "std       112.931524     112.972661     112.964176      63.547016   \n",
      "min         1.000000       1.000000       1.000000       1.000000   \n",
      "25%         2.000000       2.000000       2.000000       2.000000   \n",
      "50%       180.000000     180.000000     180.000000       7.000000   \n",
      "75%       222.000000     222.000000     222.000000      93.000000   \n",
      "max       302.000000     304.000000     304.000000     302.000000   \n",
      "\n",
      "                f297  \n",
      "count  367694.000000  \n",
      "mean      108.344012  \n",
      "std       109.370975  \n",
      "min         1.000000  \n",
      "25%         2.000000  \n",
      "50%        92.000000  \n",
      "75%       219.000000  \n",
      "max       302.000000  \n",
      "\n",
      "[8 rows x 161 columns]\n"
     ]
    }
   ],
   "source": [
    "ds1 = df_train.describe()\n",
    "print(ds1)\n",
    "ds1.to_csv(\"../statsfile/stats1.csv\",mode=\"a\")\n",
    "ds2 = df_test.describe()\n",
    "print(ds2)\n",
    "ds2.to_csv(\"../statsfile/stats1.csv\",mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(missing_values_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "ten2fifty_percent_na_cols_train = missing_values_train[missing_values_train[\"% of Total Values\"]>6].index.tolist() \n",
    "print(len(ten2fifty_percent_na_cols_train))\n",
    "zero2ten_percent_na_cols_train = missing_values_train[missing_values_train[\"% of Total Values\"]<=6].index.tolist() \n",
    "print(len(zero2ten_percent_na_cols_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "ten2fifty_percent_na_cols_test = missing_values_test[missing_values_test[\"% of Total Values\"]>6].index.tolist() \n",
    "print(len(ten2fifty_percent_na_cols_test))\n",
    "zero2ten_percent_na_cols_test = missing_values_test[missing_values_test[\"% of Total Values\"]<=6].index.tolist() \n",
    "print(len(zero2ten_percent_na_cols_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "ten2fifty_percent_na_cols = list(set(ten2fifty_percent_na_cols_train+ten2fifty_percent_na_cols_test))\n",
    "print(len(ten2fifty_percent_na_cols))\n",
    "zero2ten_percent_na_cols = list(set(zero2ten_percent_na_cols_train+zero2ten_percent_na_cols_test))\n",
    "print(len(zero2ten_percent_na_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an nan flag column\n",
    "ten2fifty_percent_na_cols_nan = []\n",
    "for col in ten2fifty_percent_na_cols:\n",
    "    col_name = col+\"_nan\"\n",
    "    ten2fifty_percent_na_cols_nan.append(col_name)\n",
    "    df_train[col_name] = 0\n",
    "    df_train.loc[df_train[col].isnull(),col_name] = 1\n",
    "    df_test[col_name] = 0\n",
    "    df_test.loc[df_test[col].isnull(),col_name] = 1\n",
    "    df_train[col_name] = df_train[col_name].astype(np.uint8)\n",
    "    df_test[col_name] = df_test[col_name].astype(np.uint8)\n",
    "#     df_train.loc[df_train[col_name],col_name].astype(np.uint8)\n",
    "#     df_test.loc[df_test[col_name],col_name].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten2fifty_percent_cols_na = ten2fifty_percent_na_cols+ten2fifty_percent_na_cols_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ten2fifty_percent_na_cols_train = df_train[ten2fifty_percent_cols_na]\n",
    "df_train.drop(labels=ten2fifty_percent_cols_na,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ten2fifty_percent_na_cols_test = df_test[ten2fifty_percent_cols_na]\n",
    "df_test.drop(labels=ten2fifty_percent_cols_na,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (994731, 61)\n",
      "testing data shape: (500538, 61)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data shape:\", df_train.shape)\n",
    "print(\"testing data shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['f1', 'f2', 'f3', 'f4', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12',\n",
      "       'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f211', 'f212', 'f213',\n",
      "       'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222',\n",
      "       'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231',\n",
      "       'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240',\n",
      "       'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249',\n",
      "       'f250', 'f251', 'f252', 'f253'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "mice_cols = df_train.columns\n",
    "print(mice_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train_id,df_train,df_ten2fifty_percent_na_cols_train],axis=1)\n",
    "df_test = pd.concat([df_test_id,df_test,df_ten2fifty_percent_na_cols_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train_id,df_ten2fifty_percent_na_cols_train,df_test_id,df_ten2fifty_percent_na_cols_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (994731, 264)\n",
      "testing data shape: (500538, 263)\n"
     ]
    }
   ],
   "source": [
    "print(\"training data shape:\", df_train.shape)\n",
    "print(\"testing data shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date          label             f1             f2  \\\n",
      "count  9.947310e+05  994731.000000  994731.000000  994731.000000   \n",
      "mean   2.017098e+07       0.016936       0.726283       0.500948   \n",
      "std    6.011735e+01       0.129033       0.651947       0.500363   \n",
      "min    2.017090e+07       0.000000       0.000000       0.000000   \n",
      "25%    2.017092e+07       0.000000       0.000000       0.000000   \n",
      "50%    2.017101e+07       0.000000       1.000000       1.000000   \n",
      "75%    2.017102e+07       0.000000       1.000000       1.000000   \n",
      "max    2.017110e+07       1.000000       2.000000       2.000000   \n",
      "\n",
      "                  f3             f4             f6             f7  \\\n",
      "count  994731.000000  994731.000000  994731.000000  994731.000000   \n",
      "mean        0.699285       0.525461       0.701303       4.201802   \n",
      "std         0.640534       0.523872       0.757799       1.922035   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       3.000000   \n",
      "50%         1.000000       1.000000       1.000000       4.000000   \n",
      "75%         1.000000       1.000000       1.000000       6.000000   \n",
      "max         2.000000       2.000000       4.000000       7.000000   \n",
      "\n",
      "                  f8             f9      ...             f293_nan  \\\n",
      "count  994731.000000  994731.000000      ...        994731.000000   \n",
      "mean        1.404783       0.610099      ...             0.208685   \n",
      "std         0.579449       0.589819      ...             0.406369   \n",
      "min         0.000000       0.000000      ...             0.000000   \n",
      "25%         1.000000       0.000000      ...             0.000000   \n",
      "50%         1.000000       1.000000      ...             0.000000   \n",
      "75%         2.000000       1.000000      ...             0.000000   \n",
      "max         2.000000       2.000000      ...             1.000000   \n",
      "\n",
      "            f262_nan       f181_nan       f269_nan       f267_nan  \\\n",
      "count  994731.000000  994731.000000  994731.000000  994731.000000   \n",
      "mean        0.136741       0.136741       0.136741       0.136741   \n",
      "std         0.343574       0.343574       0.343574       0.343574   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "            f208_nan       f286_nan       f202_nan       f183_nan  \\\n",
      "count  994731.000000  994731.000000  994731.000000  994731.000000   \n",
      "mean        0.136741       0.208685       0.136741       0.136741   \n",
      "std         0.343574       0.406369       0.343574       0.343574   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "            f263_nan  \n",
      "count  994731.000000  \n",
      "mean        0.136741  \n",
      "std         0.343574  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 263 columns]\n",
      "               date             f1             f2             f3  \\\n",
      "count  5.005380e+05  500538.000000  500538.000000  500538.000000   \n",
      "mean   2.018024e+07       0.782956       0.499778       0.764018   \n",
      "std    3.813064e+01       0.673424       0.500012       0.665964   \n",
      "min    2.018021e+07       0.000000       0.000000       0.000000   \n",
      "25%    2.018021e+07       0.000000       0.000000       0.000000   \n",
      "50%    2.018022e+07       1.000000       0.000000       1.000000   \n",
      "75%    2.018030e+07       1.000000       1.000000       1.000000   \n",
      "max    2.018031e+07       2.000000       2.000000       2.000000   \n",
      "\n",
      "                  f4             f6             f7             f8  \\\n",
      "count  500538.000000  500538.000000  500538.000000  500538.000000   \n",
      "mean        0.533124       0.801240       4.038343       1.400223   \n",
      "std         0.530509       0.864518       1.922538       0.583340   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       2.000000       1.000000   \n",
      "50%         1.000000       1.000000       4.000000       1.000000   \n",
      "75%         1.000000       1.000000       6.000000       2.000000   \n",
      "max         2.000000       4.000000       7.000000       2.000000   \n",
      "\n",
      "                  f9            f10      ...             f293_nan  \\\n",
      "count  500538.000000  500538.000000      ...        500538.000000   \n",
      "mean        0.640163       0.902341      ...             0.265402   \n",
      "std         0.609232       0.701122      ...             0.441548   \n",
      "min         0.000000       0.000000      ...             0.000000   \n",
      "25%         0.000000       0.000000      ...             0.000000   \n",
      "50%         1.000000       1.000000      ...             0.000000   \n",
      "75%         1.000000       1.000000      ...             1.000000   \n",
      "max         2.000000       2.000000      ...             1.000000   \n",
      "\n",
      "            f262_nan       f181_nan       f269_nan       f267_nan  \\\n",
      "count  500538.000000  500538.000000  500538.000000  500538.000000   \n",
      "mean        0.183367       0.252594       0.183367       0.183367   \n",
      "std         0.386967       0.434501       0.386967       0.386967   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       1.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "            f208_nan       f286_nan       f202_nan       f183_nan  \\\n",
      "count  500538.000000  500538.000000  500538.000000  500538.000000   \n",
      "mean        0.252594       0.265402       0.252594       0.252594   \n",
      "std         0.434501       0.441548       0.434501       0.434501   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         1.000000       1.000000       1.000000       1.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "            f263_nan  \n",
      "count  500538.000000  \n",
      "mean        0.183367  \n",
      "std         0.386967  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 262 columns]\n"
     ]
    }
   ],
   "source": [
    "ds1 = df_train.describe()\n",
    "print(ds1)\n",
    "ds1.to_csv(\"../statsfile/stats1.csv\",mode=\"a\")\n",
    "ds2 = df_test.describe()\n",
    "print(ds2)\n",
    "ds2.to_csv(\"../statsfile/stats1.csv\",mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[zero2ten_percent_na_cols] = df_train[zero2ten_percent_na_cols].fillna(0)\n",
    "df_test[zero2ten_percent_na_cols] = df_test[zero2ten_percent_na_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"../transdata/train_impute_v2.csv\",header=True,index=False)\n",
    "df_test.to_csv(\"../transdata/test_impute_v2.csv\",header=True,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               date          label             f1             f2  \\\n",
      "count  9.900060e+05  990006.000000  990006.000000  990006.000000   \n",
      "mean   2.017098e+07       0.012244       0.725547       0.500877   \n",
      "std    6.012682e+01       0.109975       0.651604       0.500365   \n",
      "min    2.017090e+07       0.000000       0.000000       0.000000   \n",
      "25%    2.017092e+07       0.000000       0.000000       0.000000   \n",
      "50%    2.017101e+07       0.000000       1.000000       1.000000   \n",
      "75%    2.017102e+07       0.000000       1.000000       1.000000   \n",
      "max    2.017110e+07       1.000000       2.000000       2.000000   \n",
      "\n",
      "                  f3             f4             f6             f7  \\\n",
      "count  990006.000000  990006.000000  990006.000000  990006.000000   \n",
      "mean        0.698765       0.524773       0.698620       4.206560   \n",
      "std         0.640286       0.523246       0.753708       1.921513   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       3.000000   \n",
      "50%         1.000000       1.000000       1.000000       4.000000   \n",
      "75%         1.000000       1.000000       1.000000       6.000000   \n",
      "max         2.000000       2.000000       4.000000       7.000000   \n",
      "\n",
      "                  f8             f9      ...             f275_nan  \\\n",
      "count  990006.000000  990006.000000      ...        990006.000000   \n",
      "mean        1.404481       0.607671      ...             0.135801   \n",
      "std         0.579668       0.588218      ...             0.342578   \n",
      "min         0.000000       0.000000      ...             0.000000   \n",
      "25%         1.000000       0.000000      ...             0.000000   \n",
      "50%         1.000000       1.000000      ...             0.000000   \n",
      "75%         2.000000       1.000000      ...             0.000000   \n",
      "max         2.000000       2.000000      ...             1.000000   \n",
      "\n",
      "             f24_nan       f198_nan       f291_nan       f169_nan  \\\n",
      "count  990006.000000  990006.000000  990006.000000  990006.000000   \n",
      "mean        0.208115       0.135801       0.208115       0.135801   \n",
      "std         0.405960       0.342578       0.405960       0.342578   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "            f296_nan       f271_nan       f178_nan         f5_nan  \\\n",
      "count  990006.000000  990006.000000  990006.000000  990006.000000   \n",
      "mean        0.208115       0.135801       0.135801       0.200330   \n",
      "std         0.405960       0.342578       0.342578       0.400248   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         0.000000       0.000000       0.000000       0.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "            f268_nan  \n",
      "count  990006.000000  \n",
      "mean        0.135801  \n",
      "std         0.342578  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 263 columns]\n",
      "               date             f1             f2             f3  \\\n",
      "count  5.005380e+05  500538.000000  500538.000000  500538.000000   \n",
      "mean   2.018024e+07       0.782956       0.499778       0.764018   \n",
      "std    3.813064e+01       0.673424       0.500012       0.665964   \n",
      "min    2.018021e+07       0.000000       0.000000       0.000000   \n",
      "25%    2.018021e+07       0.000000       0.000000       0.000000   \n",
      "50%    2.018022e+07       1.000000       0.000000       1.000000   \n",
      "75%    2.018030e+07       1.000000       1.000000       1.000000   \n",
      "max    2.018031e+07       2.000000       2.000000       2.000000   \n",
      "\n",
      "                  f4             f6             f7             f8  \\\n",
      "count  500538.000000  500538.000000  500538.000000  500538.000000   \n",
      "mean        0.533124       0.801240       4.038343       1.400223   \n",
      "std         0.530509       0.864518       1.922538       0.583340   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       2.000000       1.000000   \n",
      "50%         1.000000       1.000000       4.000000       1.000000   \n",
      "75%         1.000000       1.000000       6.000000       2.000000   \n",
      "max         2.000000       4.000000       7.000000       2.000000   \n",
      "\n",
      "                  f9            f10      ...             f275_nan  \\\n",
      "count  500538.000000  500538.000000      ...        500538.000000   \n",
      "mean        0.640163       0.902341      ...             0.183367   \n",
      "std         0.609232       0.701122      ...             0.386967   \n",
      "min         0.000000       0.000000      ...             0.000000   \n",
      "25%         0.000000       0.000000      ...             0.000000   \n",
      "50%         1.000000       1.000000      ...             0.000000   \n",
      "75%         1.000000       1.000000      ...             0.000000   \n",
      "max         2.000000       2.000000      ...             1.000000   \n",
      "\n",
      "             f24_nan       f198_nan       f291_nan       f169_nan  \\\n",
      "count  500538.000000  500538.000000  500538.000000  500538.000000   \n",
      "mean        0.265402       0.252594       0.265402       0.252594   \n",
      "std         0.441548       0.434501       0.441548       0.434501   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         1.000000       1.000000       1.000000       1.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "            f296_nan       f271_nan       f178_nan         f5_nan  \\\n",
      "count  500538.000000  500538.000000  500538.000000  500538.000000   \n",
      "mean        0.265402       0.183367       0.252594       0.264272   \n",
      "std         0.441548       0.386967       0.434501       0.440945   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       0.000000       0.000000       0.000000   \n",
      "50%         0.000000       0.000000       0.000000       0.000000   \n",
      "75%         1.000000       0.000000       1.000000       1.000000   \n",
      "max         1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "            f268_nan  \n",
      "count  500538.000000  \n",
      "mean        0.183367  \n",
      "std         0.386967  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 262 columns]\n"
     ]
    }
   ],
   "source": [
    "ds1 = df_train.describe()\n",
    "print(ds1)\n",
    "ds1.to_csv(\"../statsfile/stats1.csv\",mode=\"a\")\n",
    "ds2 = df_test.describe()\n",
    "print(ds2)\n",
    "ds2.to_csv(\"../statsfile/stats1.csv\",mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive Correlations:\n",
      " f264_nan    0.097721\n",
      "f190_nan    0.097721\n",
      "f177_nan    0.097721\n",
      "f184_nan    0.097721\n",
      "f197_nan    0.097721\n",
      "f179_nan    0.097721\n",
      "f6          0.126411\n",
      "f264        0.149677\n",
      "f28         0.162565\n",
      "f29         0.165072\n",
      "f261        0.166892\n",
      "f260        0.181916\n",
      "f271        0.185304\n",
      "f53         0.195208\n",
      "f259        0.197449\n",
      "f52         0.205588\n",
      "f270        0.215005\n",
      "f30         0.240223\n",
      "f31         0.242512\n",
      "label       1.000000\n",
      "Name: label, dtype: float64\n",
      "\n",
      "Most Negative Correlations:\n",
      " f7     -0.098654\n",
      "f12    -0.091472\n",
      "f14    -0.076725\n",
      "f18    -0.065231\n",
      "f17    -0.064874\n",
      "f185   -0.061517\n",
      "f16    -0.056067\n",
      "f184   -0.055365\n",
      "f15    -0.054209\n",
      "f183   -0.045445\n",
      "f210   -0.040381\n",
      "f13    -0.031939\n",
      "f182   -0.029063\n",
      "f209   -0.026573\n",
      "f19    -0.024366\n",
      "f178   -0.023836\n",
      "f177   -0.017487\n",
      "f176   -0.010553\n",
      "f208   -0.010066\n",
      "f285   -0.009610\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find correlations with the target and sort\n",
    "correlations = df_train.corr()['label'].sort_values()\n",
    "# Display correlations\n",
    "print('Most Positive Correlations:\\n', correlations.tail(20))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations.to_csv(\"../statsfile/stats_corr.csv\",mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "f_cols = list(set(set(df_train.columns)-set([\"id\",\"label\",\"date\"]))-set(ten2fifty_percent_na_cols))\n",
    "print(len(f_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe for polynomial features,\n",
    "poly_features = df_train[['f7', 'f12', 'f14', 'f18','f17', 'f31','f30','f270','f52','f259','label']]\n",
    "poly_features_test = df_test[['f7', 'f12', 'f14', 'f18','f17', 'f31','f30','f270','f52','f259']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer for handling missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy = 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_target = poly_features['label']\n",
    "\n",
    "poly_features = poly_features.drop(columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to impute missing values\n",
    "poly_features = imputer.fit_transform(poly_features)\n",
    "poly_features_test = imputer.transform(poly_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "                                  \n",
    "# Create the polynomial object with specified degree\n",
    "poly_transformer = PolynomialFeatures(degree = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Features shape:  (990006, 286)\n"
     ]
    }
   ],
   "source": [
    "# Train the polynomial features\n",
    "poly_transformer.fit(poly_features)\n",
    "\n",
    "# Transform the features\n",
    "poly_features = poly_transformer.transform(poly_features)\n",
    "poly_features_test = poly_transformer.transform(poly_features_test)\n",
    "print('Polynomial Features shape: ', poly_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " 'f7',\n",
       " 'f12',\n",
       " 'f14',\n",
       " 'f18',\n",
       " 'f17',\n",
       " 'f31',\n",
       " 'f30',\n",
       " 'f270',\n",
       " 'f52',\n",
       " 'f259',\n",
       " 'f7^2',\n",
       " 'f7 f12',\n",
       " 'f7 f14',\n",
       " 'f7 f18']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_transformer.get_feature_names(input_features = ['f7', 'f12', 'f14', 'f18','f17', 'f31','f30','f270','f52','f259'])[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the features \n",
    "poly_features = pd.DataFrame(poly_features, \n",
    "                             columns = poly_transformer.get_feature_names(['f7', 'f12', 'f14', 'f18','f17', 'f31','f30','f270','f52','f259']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the features \n",
    "poly_features_test = pd.DataFrame(poly_features_test, \n",
    "                             columns = poly_transformer.get_feature_names(['f7', 'f12', 'f14', 'f18','f17', 'f31','f30','f270','f52','f259']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in the target\n",
    "poly_features['label'] = poly_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-a931b67e4292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpoly_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../transdata/poly_features_train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpoly_features_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../transdata/poly_features_test.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "poly_features.to_csv(\"../transdata/poly_features_train.csv\",header=True,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of the features \n",
    "poly_features_test = pd.DataFrame(poly_features_test, \n",
    "                             columns = poly_transformer.get_feature_names(['f7', 'f12', 'f14', 'f18','f17', 'f31','f30','f270','f52','f259']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features_test.to_csv(\"../transdata/poly_features_test.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train, df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlations with the target\n",
    "poly_corrs = poly_features.corr()['label'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f18^2 f52      -0.002269\n",
      "f12^2 f52      -0.002243\n",
      "f18 f17 f52    -0.002221\n",
      "f18 f52        -0.002212\n",
      "f12 f18 f52    -0.002075\n",
      "f7 f18 f52     -0.002051\n",
      "f12 f52        -0.002021\n",
      "f17 f52        -0.001859\n",
      "f7 f17 f52     -0.001802\n",
      "f12 f52 f259   -0.001740\n",
      "Name: label, dtype: float64\n",
      "f12 f14 f17    0.001879\n",
      "f12^2 f17      0.001906\n",
      "f12 f17^2      0.002002\n",
      "label          1.000000\n",
      "1                   NaN\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Display most negative and most positive\n",
    "print(poly_corrs.head(10))\n",
    "print(poly_corrs.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
